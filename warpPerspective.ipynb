{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4463e734-5d9d-482d-b57e-8d40d8b6bdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.18\n",
      "pip 23.3.1 from D:\\Programs\\anaconda3\\envs\\crowdyolo78\\lib\\site-packages\\pip (python 3.8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c8ac88-76e7-4879-8558-a2823da8bc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\models\\\\19.YolocrowdDensity\\\\yolov7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d456385-05fa-4d96-99b3-3e947b15834c",
   "metadata": {},
   "source": [
    "## Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f34d8b9-4f74-4263-a813-2046ebac8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('data/document.jpg')\n",
    "\n",
    "# Pixel values in the original image\n",
    "input_points = np.float32([[83, 18], [342, 53], [14, 389], [295, 436]])\n",
    "\n",
    "# Output image size\n",
    "width = 400\n",
    "height = int(width * 1.414)  # for A4\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Warped perspective', img_output)\n",
    "\n",
    "# cv2.imwrite('output/document.jpg', img_output)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "225b8662-1f6f-4148-9258-e4dda67e5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('data/cards.jpg')\n",
    "\n",
    "# Pixel values in the original image\n",
    "input_points = np.float32([[222, 90], [431, 133], [159, 384], [372, 431]])\n",
    "\n",
    "# Output image size\n",
    "width = 400\n",
    "height = int(width * 1.414)  # for A4\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Warped perspective', img_output)\n",
    "\n",
    "# cv2.imwrite('output/document.jpg', img_output)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d246af9b-4cda-4680-9c63-9aa9f0330ef6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m biggest\n\u001b[0;32m     19\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m img_original \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Image modification\u001b[39;00m\n\u001b[0;32m     23\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 1000:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.015 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "    return biggest\n",
    "\n",
    "\n",
    "img = cv2.imread('document.jpg')\n",
    "img_original = img.copy()\n",
    "\n",
    "# Image modification\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 20, 30, 30)\n",
    "edged = cv2.Canny(gray, 10, 20)\n",
    "\n",
    "# Contour detection\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "biggest = biggest_contour(contours)\n",
    "\n",
    "cv2.drawContours(img, [biggest], -1, (0, 255, 0), 3)\n",
    "\n",
    "# Pixel values in the original image\n",
    "points = biggest.reshape(4, 2)\n",
    "input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "points_sum = points.sum(axis=1)\n",
    "input_points[0] = points[np.argmin(points_sum)]\n",
    "input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "points_diff = np.diff(points, axis=1)\n",
    "input_points[1] = points[np.argmin(points_diff)]\n",
    "input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "(top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "right_height = np.sqrt(((top_right[0] - bottom_right[0]) ** 2) + ((top_right[1] - bottom_right[1]) ** 2))\n",
    "left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "# Output image size\n",
    "max_width = max(int(bottom_width), int(top_width))\n",
    "# max_height = max(int(right_height), int(left_height))\n",
    "max_height = int(max_width * 1.414)  # for A4\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img_original, matrix, (max_width, max_height))\n",
    "\n",
    "# Image shape modification for hstack\n",
    "gray = np.stack((gray,) * 3, axis=-1)\n",
    "edged = np.stack((edged,) * 3, axis=-1)\n",
    "\n",
    "img_hor = np.hstack((img_original, gray, edged, img))\n",
    "cv2.imshow(\"Contour detection\", img_hor)\n",
    "cv2.imshow(\"Warped perspective\", img_output)\n",
    "\n",
    "# cv2.imwrite('output/document.jpg', img_output)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1603a659-cf96-4add-962b-7d7bc4666a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('data/people.jpg')\n",
    "\n",
    "# pixel values in original image\n",
    "#inputPoints = np.float32([[0, 0], [img.shape[1], 0], [0, img.shape[1]], [img.shape[1], img.shape[1]]])\n",
    "#inputPoints = np.float32([[0, 0], [1836, 0], [0, 971], [1836, 971]])\n",
    "inputPoints = np.float32([[402, 86], [1424, 82], [0, 966], [1836, 971]])\n",
    "\n",
    "# output image size\n",
    "# width1 = 500\n",
    "# height1 = 500\n",
    "\n",
    "# width1 = 400\n",
    "# height1 = int(width * 1.414)  # for A4\n",
    "\n",
    "height = 400\n",
    "width = int(height * 1.414)\n",
    "\n",
    "# desired points values in the output image\n",
    "convertedPoints = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "\n",
    "# perspective transformation\n",
    "matrix1 = cv2. getPerspectiveTransform(inputPoints, convertedPoints)\n",
    "imgOutput = cv2.warpPerspective(img1, matrix1, (width1, height1))\n",
    "\n",
    "cv2.imshow('Original', img1)\n",
    "cv2.imshow('Warped perspective', imgOutput)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87157bf4-9a6e-4564-8210-31d4dda2b903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e70df0-70e8-48a2-8fe6-7edfdf02f133",
   "metadata": {},
   "source": [
    "## Perspective mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fc2c41bd-a414-4027-923f-181124d91ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234 238 243]\n"
     ]
    }
   ],
   "source": [
    "pixel_value = img[18, 83]\n",
    "print(pixel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "14264ea3-04e6-460b-903e-2cc1dd68895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('data/chess.jpg')\n",
    "\n",
    "# Pixel values in the original image\n",
    "input_points = np.float32([[207, 209], [614, 209], [168, 390], [661, 390]])\n",
    "\n",
    "# Output image size\n",
    "# width = 400\n",
    "# height = int(width * 1.414)  # for A4\n",
    "height = 400\n",
    "width = int(height * 1.414)\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Warped perspective', img_output)\n",
    "\n",
    "# cv2.imwrite('output/document.jpg', img_output)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "351dadbd-fa16-4017-86c0-9ebdc0154ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('data/chess.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(img, 50, 150, apertureSize=3)\n",
    "\n",
    "# Use Hough Line Transform to find lines\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "\n",
    "# Find intersection points of lines\n",
    "intersections = []\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "    intersections.append((x1, y1))\n",
    "\n",
    "# Take the first 4 intersection points\n",
    "input_points = np.float32(intersections[:4])\n",
    "\n",
    "# Output image size\n",
    "height = 400\n",
    "width = int(height * 1.414)\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Warped perspective', img_output)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0e822307-a266-4b7b-86a3-31ceb2724f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\programs\\anaconda3\\envs\\crowdyolo78\\lib\\site-packages (from opencv-contrib-python) (1.23.5)\n",
      "Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl (45.3 MB)\n",
      "   ---------------------------------------- 0.0/45.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/45.3 MB 1.7 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 0.4/45.3 MB 3.6 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.7/45.3 MB 4.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.2/45.3 MB 6.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.4/45.3 MB 5.9 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 2.0/45.3 MB 6.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.5/45.3 MB 7.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 3.0/45.3 MB 7.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.5/45.3 MB 7.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.9/45.3 MB 8.1 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 4.4/45.3 MB 8.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.9/45.3 MB 8.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.4/45.3 MB 8.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.9/45.3 MB 8.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.5/45.3 MB 9.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.0/45.3 MB 9.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.5/45.3 MB 9.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.0/45.3 MB 9.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.5/45.3 MB 9.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 9.0/45.3 MB 9.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.5/45.3 MB 9.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 10.0/45.3 MB 9.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.5/45.3 MB 10.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.0/45.3 MB 10.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.7/45.3 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 12.4/45.3 MB 10.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.9/45.3 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.5/45.3 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.0/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.5/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.0/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.5/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.1/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.6/45.3 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.1/45.3 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.7/45.3 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.2/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.9/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.4/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.0/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.5/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.1/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.6/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.1/45.3 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.7/45.3 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.2/45.3 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.7/45.3 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.3/45.3 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.8/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.4/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.0/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.6/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.1/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.7/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.2/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.7/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.3/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.8/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.3/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.9/45.3 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.6/45.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.1/45.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.7/45.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.2/45.3 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.7/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.3/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.8/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.3/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.9/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.4/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.9/45.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.7/45.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.2/45.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.4/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.1/45.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.5/45.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/45.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.9/45.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.3/45.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.6/45.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.9/45.3 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.2/45.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.5/45.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.8/45.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.0/45.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.3/45.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.6/45.3 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.9/45.3 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.2/45.3 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.5/45.3 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.8/45.3 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.1/45.3 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.4/45.3 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/45.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.1/45.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.2/45.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.3/45.3 MB 7.4 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524b224-2389-45af-a5d6-31207642219c",
   "metadata": {},
   "source": [
    "## Video warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8f6bab90-c0bc-4631-ba68-9c2695653b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture('person720.mp4')  # Replace 'your_video.mp4' with the path to your video file\n",
    "\n",
    "# Output image size\n",
    "# width = 400\n",
    "# height = int(width * 1.414)  # for A4\n",
    "height = 400\n",
    "width = int(height * 1.414)\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Pixel values in the original frame (you may need to modify this part)\n",
    "    input_points = np.float32([[345, 70], [874, 70], [47, 696], [1134, 696]]) # correct warp\n",
    "    #input_points = np.float32([[80, 55], [1074, 55], [80, 700], [1074, 700]])   # rect\n",
    "    #input_points = np.float32([[200, 55], [966, 55], [80, 700], [1074, 700]])  # img like\n",
    "\n",
    "    # Perspective transformation\n",
    "    matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "    frame_output = cv2.warpPerspective(frame, matrix, (width, height))\n",
    "    \n",
    "\n",
    "    # Display the original and warped frames\n",
    "    cv2.imshow('Original', frame)\n",
    "    cv2.imshow('Warped perspective', frame_output)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    key = cv2.waitKey(int(1000 / 18)) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470fd4c-fff9-4f6d-aa1d-214ddd80be61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e5d098cf-c630-43b9-88a5-eec715f5e03d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture('person720.mp4')  # Replace 'your_video.mp4' with the path to your video file\n",
    "\n",
    "# Output image size\n",
    "height = 400\n",
    "width = int(height * 1.414)\n",
    "\n",
    "# Desired points values in the output image\n",
    "converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale and threshold it\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find the contours in the thresholded image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour by area\n",
    "    max_area = 0\n",
    "    largest_contour = None\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_contour = c\n",
    "\n",
    "    # Approximate the largest contour to a quadrilateral\n",
    "    epsilon = 0.1 * cv2.arcLength(largest_contour, True)\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "\n",
    "    # Check if the approximation has four vertices\n",
    "    if len(approx) == 4:\n",
    "        # Use the vertices as the input points\n",
    "        input_points = approx.reshape(4, 2).astype(np.float32)\n",
    "\n",
    "        # Sort the input points by x-coordinate\n",
    "        input_points = input_points[np.argsort(input_points[:, 0])]\n",
    "\n",
    "        # Swap the points if the top-left point has a larger y-coordinate than the bottom-left point\n",
    "        if input_points[0, 1] > input_points[1, 1]:\n",
    "            input_points[[0, 1]] = input_points[[1, 0]]\n",
    "\n",
    "        # Swap the points if the bottom-right point has a larger y-coordinate than the top-right point\n",
    "        if input_points[2, 1] > input_points[3, 1]:\n",
    "            input_points[[2, 3]] = input_points[[3, 2]]\n",
    "\n",
    "        # Perspective transformation\n",
    "        matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "        frame_output = cv2.warpPerspective(frame, matrix, (width, height))\n",
    "\n",
    "        # Rotate the output image by 90 degrees clockwise\n",
    "        frame_output = cv2.rotate(frame_output, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # Flip the output image horizontally\n",
    "        frame_output = cv2.flip(frame_output, 1)\n",
    "\n",
    "        # Display the original and warped frames\n",
    "        cv2.imshow('Original', frame)\n",
    "        cv2.imshow('Warped perspective', frame_output)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    key = cv2.waitKey(int(1000 / 18)) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# just showing everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc5ccb-e775-4cab-a0d7-935672860a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crowdyolo78",
   "language": "python",
   "name": "crowdyolo78"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
